{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9f197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L =  4\n",
      "n =  [4, 9, 5, 1]\n",
      "xi =  [array([0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0.]), array([0.])]\n",
      "xi[0] =  [0. 0. 0. 0.]\n",
      "xi[1] =  [0. 0. 0. 0.]\n",
      "wh =  [array([[0.]]), array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0.]])]\n",
      "wh[1] =  [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from NeuralNet import NeuralNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffd1f1",
   "metadata": {},
   "source": [
    "Part 1: Dataset selection\n",
    "Source Webpage: [Kaggle House Prices Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6bccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Display basic information\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb15cbb",
   "metadata": {},
   "source": [
    "Part 2: Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a0a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice'] = np.log1p(df['SalePrice'])\n",
    "df = df.drop(df[(df['GrLivArea']>4000) & (df['SalePrice']<12.5)].index)\n",
    "\n",
    "X = df.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = df['SalePrice'].to_numpy()\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2373bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1166, 299)\n",
      "Testing data shape: (292, 299)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train).toarray()\n",
    "X_test_scaled = preprocessor.transform(X_test).toarray()\n",
    "\n",
    "print(\"Training data shape:\", X_train_scaled.shape)\n",
    "print(\"Testing data shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd435df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('data.npz', X_train=X_train_scaled, y_train=y_train, X_test=X_test_scaled, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202815c3",
   "metadata": {},
   "source": [
    "Part 3: Obtaining and comparing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4115a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "    print(f\"--- {model_name} Evaluation ---\")\n",
    "    print(f\"MSE:  ${mse:,.2f}\")\n",
    "    print(f\"MAE:  ${mae:,.2f}\")\n",
    "    print(f\"MAPE: {mape:.2%}\")\n",
    "\n",
    "    return {'Model': model_name, 'MSE': mse, 'MAE': mae, 'MAPE': mape}\n",
    "\n",
    "def plot_predictions(y_true, y_pred, model_name):\n",
    "    plt.figure()\n",
    "    plt.scatter(y_true, y_pred, label='Predictions')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], label='Ideal Fit')\n",
    "    plt.xlabel(\"Actual Sale Price (Log)\")\n",
    "    plt.ylabel(\"Predicted Sale Price (Log)\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(train_loss, val_loss, model_name):\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d09f7",
   "metadata": {},
   "source": [
    "Part 3.1: BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353c68c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Combination 1/5 ---\n",
      "Params: {'layers': [299, 64, 1], 'lr': 0.01, 'mom': 0.5, 'act': 'sigmoid', 'epochs': 100}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NeuralNet.__init__() got an unexpected keyword argument 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Training Combination \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(hyperparameters)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m nn = \u001b[43mNeuralNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlayers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmom\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mact\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m nn.fit(X_train_scaled, y_train)\n\u001b[32m     28\u001b[39m y_pred = nn.predict(X_test_scaled)\n",
      "\u001b[31mTypeError\u001b[39m: NeuralNet.__init__() got an unexpected keyword argument 'learning_rate'"
     ]
    }
   ],
   "source": [
    "# TODO: Implement the NN training and evaluation loop\n",
    "\n",
    "n_features = X_train_scaled.shape[1]\n",
    "hyperparameters = [\n",
    "    {'layers': [n_features, 64, 1], 'lr': 0.01, 'mom': 0.5, 'act': 'sigmoid', 'epochs': 100},\n",
    "    {'layers': [n_features, 64, 1], 'lr': 0.01, 'mom': 0.5, 'act': 'tanh', 'epochs': 100},\n",
    "    {'layers': [n_features, 64, 1], 'lr': 0.005, 'mom': 0.7, 'act': 'relu', 'epochs': 100},\n",
    "    {'layers': [n_features, 128, 1], 'lr': 0.001, 'mom': 0.9, 'act': 'relu', 'epochs': 150},\n",
    "    {'layers': [n_features, 64, 32, 1], 'lr': 0.01, 'mom': 0.5, 'act': 'relu', 'epochs': 150}\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "best_model_info = {'mae': float('inf'), 'model': None, 'params': None, 'history': None}\n",
    "\n",
    "for i, params in enumerate(hyperparameters):\n",
    "    print(f\"\\n--- Training Combination {i+1}/{len(hyperparameters)} ---\")\n",
    "    print(f\"Params: {params}\")\n",
    "\n",
    "    nn = NeuralNet(\n",
    "        layers=params['layers'],\n",
    "        learning_rate=params['lr'],\n",
    "        momentum=params['mom'],\n",
    "        activation=params['act'],\n",
    "        epochs=params['epochs']\n",
    "    )\n",
    "\n",
    "    nn.fit(X_train_scaled, y_train)\n",
    "    y_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "    eval_metrics = evaluate_model(y_test, y_pred, f\"Custom BP Combo {i+1}\")\n",
    "\n",
    "    results_list.append({\n",
    "        'Combination': i+1,\n",
    "        'Layer Structure': str(params['layers']),\n",
    "        'Num epochs': params['epochs'],\n",
    "        'Learning Rate': params['lr'],\n",
    "        'Momentum': params['mom'],\n",
    "        'Activation': params['act'],\n",
    "        'MSE': eval_metrics['MSE'],\n",
    "        'MAE': eval_metrics['MAE'],\n",
    "        'MAPE': eval_metrics['MAPE']\n",
    "    })\n",
    "    if eval_metrics['MAE'] < best_model_info['mae']:\n",
    "        best_model_info['mae'] = eval_metrics['MAE']\n",
    "        best_model_info['model'] = nn\n",
    "        best_model_info['params'] = params\n",
    "        best_model_info['history'] = nn.loss_epochs()\n",
    "        best_model_info['name'] = f\"Custom BP Combo {i+1} (Best)\"\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.sort_values(by='MAE')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb19f83",
   "metadata": {},
   "source": [
    "Part 3.2: BP, BP-F, MLR-F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ed1f6",
   "metadata": {},
   "source": [
    "Comparision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
